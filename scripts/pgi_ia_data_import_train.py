#!/usr/bin/env python3
"""
PGI-IA Data Import & DeepSeek Training Script
Import des projets Kahnawake et Alexis Nihon + entrainement DeepSeek
"""

import os
import sys
import sqlite3
import json
import hashlib
import shutil
from datetime import datetime, timedelta
import random
from pathlib import Path
import PyPDF2

# Paths
DATASET_BASE = "/mnt/c/Users/fvegi/OneDrive/Desktop/dataset/Contrats de Projets - En cours"
KAHNAWAKE_PATH = os.path.join(DATASET_BASE, "C24-060 - Centre Culturel Kahnawake - Les Entreprises QMD")
ALEXIS_PATH = os.path.join(DATASET_BASE, "C24-048 - Place Alexis-Nihon")
DB_PATH = "/root/dev/pgi-ia/pgi_ia.db"
UPLOAD_DIR = "/root/dev/pgi-ia/uploads"
TRAINING_FILE = "/mnt/c/Users/fvegi/deepseek_training_dataset.jsonl"

class DataImporter:
    def __init__(self):
        self.conn = sqlite3.connect(DB_PATH)
        self.cursor = self.conn.cursor()
        self.training_data = []
        self.ensure_upload_dir()
        
    def ensure_upload_dir(self):
        """Cr√©er le dossier uploads si n√©cessaire"""
        os.makedirs(UPLOAD_DIR, exist_ok=True)
        
    def clear_existing_data(self):
        """Nettoyer les donn√©es existantes"""
        print("üßπ Nettoyage des donn√©es existantes...")
        tables = ['documents', 'projects', 'notes', 'agents', 'system_logs']
        for table in tables:
            self.cursor.execute(f"DELETE FROM {table}")
        self.conn.commit()
        print("‚úÖ Base de donn√©es nettoy√©e")
        
    def import_projects(self):
        """Importer les projets Kahnawake et Alexis Nihon"""
        print("\nüìÅ Import des projets...")
        
        projects = [
            {
                'id': 'C24-060',
                'name': 'Centre Culturel Kahnawake',
                'client': 'Les Entreprises QMD',
                'status': 'Construction',
                'budget': 1250000.00,
                'start_date': '2024-03-15',
                'end_date': '2025-09-30',
                'completion': 35,
                'path': KAHNAWAKE_PATH
            },
            {
                'id': 'C24-048',
                'name': 'Place Alexis-Nihon Phase 3',
                'client': 'Cominar REIT',
                'status': 'Estimation',
                'budget': 850000.00,
                'start_date': '2024-06-01',
                'end_date': '2025-12-15',
                'completion': 15,
                'path': ALEXIS_PATH
            }
        ]
        
        for project in projects:
            # Compter les PDFs
            pdf_count = len(list(Path(project['path']).rglob('*.pdf')))
            
            # Adapter au sch√©ma existant
            metadata = {
                'client': project['client'],
                'budget': project['budget'],
                'start_date': project['start_date'],
                'end_date': project['end_date'],
                'completion': project['completion'],
                'pdf_count': pdf_count,
                'source_path': project['path']
            }
            
            self.cursor.execute('''
                INSERT OR REPLACE INTO projects 
                (id, name, description, status)
                VALUES (?, ?, ?, ?)
            ''', (
                project['id'],
                project['name'],
                f"{project['client']} - Budget: ${project['budget']:,.0f}",
                project['status']
            ))
            
            print(f"‚úÖ Projet {project['id']}: {project['name']} ({pdf_count} PDFs)")
            
            # Donn√©es pour entrainement DeepSeek
            self.training_data.append({
                "messages": [
                    {"role": "system", "content": "Tu es un assistant IA sp√©cialis√© en gestion de projets de construction √©lectrique."},
                    {"role": "user", "content": f"Quel est le statut du projet {project['name']}?"},
                    {"role": "assistant", "content": f"Le projet {project['name']} (code {project['id']}) pour {project['client']} est actuellement en phase de {project['status']}. Budget: {project['budget']:,.2f}$ CAD, Avancement: {project['completion']}%. P√©riode: {project['start_date']} √† {project['end_date']}. Nous avons {pdf_count} documents PDF associ√©s √† ce projet."}
                ]
            })
            
        self.conn.commit()
        
    def import_sample_documents(self, limit_per_project=50):
        """Importer un √©chantillon de documents PDF"""
        print(f"\nüìÑ Import de {limit_per_project} documents par projet...")
        
        for project_id, project_path in [('C24-060', KAHNAWAKE_PATH), ('C24-048', ALEXIS_PATH)]:
            # Trouver tous les PDFs
            pdf_files = list(Path(project_path).rglob('*.pdf'))
            
            # Prioriser les fichiers importants
            priority_keywords = ['plan', 'devis', 'directive', 'soumission', 'facture', 'rapport']
            
            # Trier par priorit√©
            priority_pdfs = []
            other_pdfs = []
            
            for pdf in pdf_files:
                if any(keyword in pdf.name.lower() for keyword in priority_keywords):
                    priority_pdfs.append(pdf)
                else:
                    other_pdfs.append(pdf)
            
            # S√©lectionner les PDFs √† importer
            selected_pdfs = priority_pdfs[:limit_per_project//2] + other_pdfs[:limit_per_project//2]
            
            for idx, pdf_path in enumerate(selected_pdfs[:limit_per_project]):
                try:
                    # Calculer hash
                    with open(pdf_path, 'rb') as f:
                        file_hash = hashlib.sha256(f.read()).hexdigest()
                    
                    # Copier vers uploads
                    dest_name = f"{project_id}_{idx:03d}_{pdf_path.name}"
                    dest_path = os.path.join(UPLOAD_DIR, dest_name)
                    shutil.copy2(pdf_path, dest_path)
                    
                    # Extraire metadata
                    file_size = os.path.getsize(pdf_path)
                    relative_path = str(pdf_path).replace(project_path, '')
                    
                    # D√©terminer le type de document
                    doc_type = 'Autre'
                    for keyword in priority_keywords:
                        if keyword in pdf_path.name.lower():
                            doc_type = keyword.capitalize()
                            break
                    
                    # Ins√©rer dans la base
                    self.cursor.execute('''
                        INSERT INTO documents 
                        (project_id, name, type, file_path, file_size, hash, upload_date, analyzed, metadata)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        project_id,
                        pdf_path.name,
                        doc_type,
                        dest_name,
                        file_size,
                        file_hash,
                        datetime.now().isoformat(),
                        0,  # Non analys√©
                        json.dumps({
                            'original_path': str(pdf_path),
                            'relative_path': relative_path,
                            'pages': self.get_pdf_pages(pdf_path)
                        })
                    ))
                    
                    # Donn√©es pour entrainement
                    self.training_data.append({
                        "messages": [
                            {"role": "system", "content": "Tu es un assistant IA expert en analyse de documents de construction √©lectrique."},
                            {"role": "user", "content": f"J'ai un document {doc_type} nomm√© '{pdf_path.name}' pour le projet {project_id}. Que peux-tu me dire?"},
                            {"role": "assistant", "content": f"Ce document '{pdf_path.name}' est un {doc_type} du projet {project_id}. Il fait {file_size/1024:.1f} KB et contient des informations importantes pour le projet. Le chemin relatif est: {relative_path}. Je peux analyser son contenu pour extraire les informations cl√©s comme les sp√©cifications techniques, les co√ªts, ou les directives de construction."}
                        ]
                    })
                    
                    if idx % 10 == 0:
                        print(f"  ‚Üí {idx+1}/{limit_per_project} documents import√©s pour {project_id}")
                        
                except Exception as e:
                    print(f"  ‚ö†Ô∏è Erreur import {pdf_path.name}: {str(e)}")
                    
        self.conn.commit()
        print("‚úÖ Documents import√©s")
        
    def get_pdf_pages(self, pdf_path):
        """Obtenir le nombre de pages d'un PDF"""
        try:
            with open(pdf_path, 'rb') as f:
                reader = PyPDF2.PdfReader(f)
                return len(reader.pages)
        except:
            return 0
            
    def generate_sample_notes(self):
        """G√©n√©rer des notes terrain r√©alistes"""
        print("\nüìù G√©n√©ration de notes terrain...")
        
        note_templates = [
            {
                'type': 'D√©ficience',
                'templates': [
                    "Panneau {location} non conforme - manque identification circuits",
                    "Conduits {location} mal fix√©s - refaire supports",
                    "Bo√Æte jonction {location} sans couvercle - s√©curit√©",
                    "C√¢blage {location} non prot√©g√© - ajouter gaine"
                ]
            },
            {
                'type': 'Directive',
                'templates': [
                    "Installer {count} prises {type} au {location}",
                    "D√©placer panneau de {old_location} vers {new_location}",
                    "Ajouter √©clairage d'urgence {location}",
                    "Remplacer disjoncteur {size}A par {new_size}A panneau {panel}"
                ]
            },
            {
                'type': 'Inspection',
                'templates': [
                    "Installation {location} compl√©t√©e - conforme plans",
                    "Test continuit√© circuits {panel} - OK",
                    "V√©rification mise √† terre {location} - r√©sistance {ohms}Œ©",
                    "Inspection finale {area} - {count} d√©ficiences mineures"
                ]
            }
        ]
        
        locations = ['local 101', 'corridor 2e', 'salle m√©canique', 'bureau admin', 'entrep√¥t', 'caf√©t√©ria']
        
        for project_id in ['C24-060', 'C24-048']:
            for i in range(30):  # 30 notes par projet
                note_type = random.choice(note_templates)
                template = random.choice(note_type['templates'])
                
                # Remplir le template
                note_text = template.format(
                    location=random.choice(locations),
                    count=random.randint(2, 10),
                    type=random.choice(['duplex', 'GFCI', 'USB', '20A']),
                    old_location='local ' + str(random.randint(100, 200)),
                    new_location='local ' + str(random.randint(201, 300)),
                    size=random.choice([15, 20, 30]),
                    new_size=random.choice([20, 30, 40]),
                    panel='P' + str(random.randint(1, 5)),
                    ohms=round(random.uniform(0.1, 2.0), 1),
                    area=random.choice(['√©tage 1', '√©tage 2', 'sous-sol'])
                )
                
                # Note reformul√©e par IA
                reformulated = f"**{note_type['type']} - {datetime.now().strftime('%Y-%m-%d')}**\n\n"
                reformulated += f"Projet: {project_id}\n"
                reformulated += f"Observation: {note_text}\n\n"
                reformulated += f"Action requise: " + random.choice([
                    "Correction imm√©diate requise pour conformit√©",
                    "√Ä compl√©ter avant inspection",
                    "Suivi avec sous-traitant n√©cessaire",
                    "Documentation √† mettre √† jour"
                ])
                
                # Ins√©rer dans la base
                self.cursor.execute('''
                    INSERT INTO notes 
                    (project_id, date, author, category, original_note, reformulated_note, 
                     confidence_score, metadata, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    project_id,
                    (datetime.now() - timedelta(days=random.randint(0, 30))).strftime('%Y-%m-%d'),
                    random.choice(['Jean Tremblay', 'Marc Dubois', 'Pierre Lavoie']),
                    note_type['type'],
                    note_text,
                    reformulated,
                    round(random.uniform(0.85, 0.98), 2),
                    json.dumps({'auto_generated': True, 'template': template}),
                    datetime.now().isoformat()
                ))
                
                # Entrainement DeepSeek
                self.training_data.append({
                    "messages": [
                        {"role": "system", "content": "Tu es un assistant IA qui reformule les notes de terrain en fran√ßais professionnel pour les rapports de construction √©lectrique."},
                        {"role": "user", "content": f"Reformule cette note de terrain: {note_text}"},
                        {"role": "assistant", "content": reformulated}
                    ]
                })
                
        self.conn.commit()
        print("‚úÖ 60 notes terrain g√©n√©r√©es")
        
    def save_training_data(self):
        """Sauvegarder les donn√©es d'entrainement pour DeepSeek"""
        print(f"\nüíæ Sauvegarde des donn√©es d'entrainement...")
        
        with open(TRAINING_FILE, 'w', encoding='utf-8') as f:
            for item in self.training_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
                
        print(f"‚úÖ {len(self.training_data)} exemples sauvegard√©s dans {TRAINING_FILE}")
        
        # Cr√©er aussi un fichier de m√©tadonn√©es
        metadata = {
            'created_at': datetime.now().isoformat(),
            'total_examples': len(self.training_data),
            'projects': ['C24-060 - Kahnawake', 'C24-048 - Alexis Nihon'],
            'categories': {
                'project_info': sum(1 for d in self.training_data if 'statut du projet' in str(d)),
                'document_analysis': sum(1 for d in self.training_data if 'document' in str(d)),
                'note_reformulation': sum(1 for d in self.training_data if 'Reformule' in str(d))
            }
        }
        
        with open(TRAINING_FILE.replace('.jsonl', '_metadata.json'), 'w') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
            
    def generate_summary(self):
        """G√©n√©rer un r√©sum√© de l'import"""
        print("\nüìä R√âSUM√â DE L'IMPORT")
        print("=" * 50)
        
        # Compter les enregistrements
        tables = ['projects', 'documents', 'notes']
        for table in tables:
            self.cursor.execute(f"SELECT COUNT(*) FROM {table}")
            count = self.cursor.fetchone()[0]
            print(f"{table.capitalize()}: {count}")
            
        # Statistiques par projet
        print("\nPar projet:")
        self.cursor.execute('''
            SELECT p.id, p.name, 
                   COUNT(DISTINCT d.id) as doc_count,
                   COUNT(DISTINCT n.id) as note_count
            FROM projects p
            LEFT JOIN documents d ON p.id = d.project_id
            LEFT JOIN notes n ON p.id = n.project_id
            GROUP BY p.id
        ''')
        
        for row in self.cursor.fetchall():
            print(f"  {row[0]} - {row[1]}: {row[2]} docs, {row[3]} notes")
            
    def run(self):
        """Ex√©cuter l'import complet"""
        print("üöÄ D√âMARRAGE IMPORT PGI-IA")
        print(f"Kahnawake: {KAHNAWAKE_PATH}")
        print(f"Alexis Nihon: {ALEXIS_PATH}")
        
        self.clear_existing_data()
        self.import_projects()
        self.import_sample_documents(limit_per_project=50)
        self.generate_sample_notes()
        self.save_training_data()
        self.generate_summary()
        
        self.conn.close()
        print("\n‚úÖ IMPORT TERMIN√â!")
        print(f"üéì Donn√©es d'entrainement DeepSeek: {TRAINING_FILE}")
        
if __name__ == "__main__":
    importer = DataImporter()
    importer.run()