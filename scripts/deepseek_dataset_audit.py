#!/usr/bin/env python3
"""
Audit complet du dataset DeepSeek pour PGI-IA
"""

import json
import re
from collections import Counter, defaultdict
import statistics

def audit_dataset(filename):
    """Analyser en profondeur le dataset"""
    
    print(f"ğŸ” AUDIT DU DATASET: {filename}")
    print("=" * 80)
    
    # Charger les donnÃ©es
    messages = []
    with open(filename, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                messages.append(json.loads(line))
            except:
                print(f"âš ï¸ Ligne invalide dÃ©tectÃ©e")
    
    print(f"\nğŸ“Š STATISTIQUES GÃ‰NÃ‰RALES")
    print(f"Total d'exemples: {len(messages)}")
    
    # 1. ANALYSE DES RÃ”LES
    print(f"\nğŸ­ ANALYSE DES RÃ”LES")
    role_counts = Counter()
    for msg in messages:
        for m in msg['messages']:
            role_counts[m['role']] += 1
    
    for role, count in role_counts.items():
        print(f"  - {role}: {count} messages")
    
    # 2. ANALYSE DES SYSTEM PROMPTS
    print(f"\nğŸ¤– TYPES DE SYSTEM PROMPTS")
    system_prompts = []
    for msg in messages:
        system_msg = next((m['content'] for m in msg['messages'] if m['role'] == 'system'), None)
        if system_msg:
            system_prompts.append(system_msg)
    
    system_types = Counter(system_prompts)
    for prompt, count in system_types.most_common(10):
        print(f"  - [{count}x] {prompt[:80]}...")
    
    # 3. ANALYSE DE LA LONGUEUR
    print(f"\nğŸ“ ANALYSE DES LONGUEURS")
    user_lengths = []
    assistant_lengths = []
    
    for msg in messages:
        for m in msg['messages']:
            if m['role'] == 'user':
                user_lengths.append(len(m['content']))
            elif m['role'] == 'assistant':
                assistant_lengths.append(len(m['content']))
    
    print(f"Questions utilisateur:")
    print(f"  - Moyenne: {statistics.mean(user_lengths):.0f} caractÃ¨res")
    print(f"  - Min/Max: {min(user_lengths)}/{max(user_lengths)}")
    
    print(f"RÃ©ponses assistant:")
    print(f"  - Moyenne: {statistics.mean(assistant_lengths):.0f} caractÃ¨res")
    print(f"  - Min/Max: {min(assistant_lengths)}/{max(assistant_lengths)}")
    
    # 4. ANALYSE DU CONTENU QUÃ‰BÃ‰COIS
    print(f"\nğŸ SPÃ‰CIFICITÃ‰ QUÃ‰BÃ‰COISE")
    quebec_keywords = ['quÃ©bec', 'ccq', 'cnesst', 'csa', 'mohawk', 'kahnawake', 
                      'hydro-quÃ©bec', 'rbq', 'premiÃ¨re nation', 'first nation',
                      'compagnon', 'cominar', 'tps', 'tvq']
    
    quebec_count = 0
    for msg in messages:
        content = json.dumps(msg, ensure_ascii=False).lower()
        if any(keyword in content for keyword in quebec_keywords):
            quebec_count += 1
    
    print(f"  - Exemples avec contexte QuÃ©bec: {quebec_count}/{len(messages)} ({quebec_count/len(messages)*100:.1f}%)")
    
    # 5. ANALYSE DES PROJETS MENTIONNÃ‰S
    print(f"\nğŸ—ï¸ PROJETS MENTIONNÃ‰S")
    project_mentions = Counter()
    project_patterns = [
        (r'[CS]\d{2}-\d{3,4}', 'Codes projets'),
        (r'kahnawake|musÃ©e', 'Kahnawake'),
        (r'alexis[\s-]?nihon', 'Alexis Nihon'),
        (r'qmd|entreprises qmd', 'QMD'),
        (r'cominar', 'Cominar')
    ]
    
    for msg in messages:
        content = json.dumps(msg, ensure_ascii=False).lower()
        for pattern, name in project_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                project_mentions[name] += 1
    
    for project, count in project_mentions.most_common():
        print(f"  - {project}: {count} mentions")
    
    # 6. ANALYSE TECHNIQUE
    print(f"\nâš¡ CONTENU TECHNIQUE Ã‰LECTRIQUE")
    tech_keywords = {
        'Panneaux': ['panneau', 'panel', 'distribution'],
        'CÃ¢blage': ['cÃ¢ble', 'conduit', 'fil', 'conducteur'],
        'Normes': ['csa', 'code Ã©lectrique', 'article', 'norme'],
        'SÃ©curitÃ©': ['cadenassage', 'sÃ©curitÃ©', 'cnesst', 'mise Ã  terre'],
        'Ã‰quipements': ['disjoncteur', 'prise', 'luminaire', 'transformateur'],
        'Documents': ['plan', 'devis', 'directive', 'facture']
    }
    
    tech_counts = defaultdict(int)
    for msg in messages:
        content = json.dumps(msg, ensure_ascii=False).lower()
        for category, keywords in tech_keywords.items():
            if any(kw in content for kw in keywords):
                tech_counts[category] += 1
    
    for category, count in sorted(tech_counts.items(), key=lambda x: x[1], reverse=True):
        print(f"  - {category}: {count} exemples ({count/len(messages)*100:.1f}%)")
    
    # 7. DÃ‰TECTION DE PROBLÃˆMES
    print(f"\nâš ï¸ PROBLÃˆMES POTENTIELS")
    problems = []
    
    # VÃ©rifier les rÃ©ponses gÃ©nÃ©riques
    generic_responses = 0
    for msg in messages:
        assistant_msg = next((m['content'] for m in msg['messages'] if m['role'] == 'assistant'), "")
        if "plans Ã©lectriques" in assistant_msg and "Ã©lÃ©ments clÃ©s incluent" in assistant_msg:
            generic_responses += 1
    
    if generic_responses > 5:
        problems.append(f"RÃ©ponses gÃ©nÃ©riques dÃ©tectÃ©es: {generic_responses} exemples utilisent la mÃªme formulation")
    
    # VÃ©rifier la diversitÃ©
    unique_questions = len(set(m['messages'][1]['content'] for m in messages if len(m['messages']) > 1))
    if unique_questions < len(messages) * 0.8:
        problems.append(f"Manque de diversitÃ©: seulement {unique_questions} questions uniques sur {len(messages)}")
    
    # VÃ©rifier l'Ã©quilibre des catÃ©gories
    if tech_counts['Documents'] > len(messages) * 0.5:
        problems.append("SurreprÃ©sentation des documents par rapport aux aspects techniques")
    
    if problems:
        for p in problems:
            print(f"  âŒ {p}")
    else:
        print("  âœ… Aucun problÃ¨me majeur dÃ©tectÃ©")
    
    # 8. RECOMMANDATIONS
    print(f"\nğŸ’¡ RECOMMANDATIONS D'AMÃ‰LIORATION")
    recommendations = []
    
    if quebec_count < len(messages) * 0.7:
        recommendations.append("Ajouter plus de contexte spÃ©cifique au QuÃ©bec (rÃ©glementation, organismes)")
    
    if tech_counts['SÃ©curitÃ©'] < 5:
        recommendations.append("Enrichir avec plus d'exemples de sÃ©curitÃ© (ASP Construction, procÃ©dures)")
    
    if 'estimation' not in str(tech_counts):
        recommendations.append("Ajouter des exemples de calculs et estimations dÃ©taillÃ©es")
    
    if not any('erreur' in json.dumps(m).lower() for m in messages):
        recommendations.append("Inclure des exemples de rÃ©solution de problÃ¨mes et erreurs courantes")
    
    for r in recommendations:
        print(f"  â†’ {r}")
    
    # 9. SCORE DE QUALITÃ‰
    print(f"\nğŸ† SCORE DE QUALITÃ‰ GLOBAL")
    scores = {
        'DiversitÃ©': min(100, (unique_questions / len(messages)) * 100),
        'SpÃ©cificitÃ© QuÃ©bec': (quebec_count / len(messages)) * 100,
        'Couverture technique': len(tech_counts) * 10,
        'Longueur rÃ©ponses': min(100, (statistics.mean(assistant_lengths) / 300) * 100),
        'Absence problÃ¨mes': 100 if not problems else 50
    }
    
    for critere, score in scores.items():
        print(f"  - {critere}: {score:.0f}/100")
    
    score_global = statistics.mean(scores.values())
    print(f"\n  ğŸ“Š SCORE GLOBAL: {score_global:.0f}/100")
    
    if score_global >= 80:
        print("  âœ… Dataset de haute qualitÃ©!")
    elif score_global >= 60:
        print("  ğŸ”¶ Dataset acceptable mais peut Ãªtre amÃ©liorÃ©")
    else:
        print("  âŒ Dataset nÃ©cessite des amÃ©liorations significatives")
    
    return score_global, problems, recommendations

if __name__ == "__main__":
    # Auditer les trois datasets
    datasets = [
        "/mnt/c/Users/fvegi/deepseek_training_construction.jsonl",
        "/mnt/c/Users/fvegi/deepseek_training_pgi_ia_enhanced.jsonl",
        "/mnt/c/Users/fvegi/deepseek_training_pgi_ia_complete.jsonl"
    ]
    
    for dataset in datasets:
        try:
            print("\n" + "="*80 + "\n")
            audit_dataset(dataset)
        except FileNotFoundError:
            print(f"âŒ Fichier non trouvÃ©: {dataset}")
        except Exception as e:
            print(f"âŒ Erreur lors de l'audit: {str(e)}")